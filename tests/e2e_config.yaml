# MCPSpy E2E Test Configuration
# ================================
# YAML-driven test configuration for MCPSpy end-to-end testing.
# This file defines test scenarios, their execution, and validation rules.

version: "1.0"

# Default settings applied to all scenarios
defaults:
  mcpspy:
    # Binary path relative to project root (where make is run)
    # Update this path if your platform is different (e.g., build/mcpspy-linux-arm64)
    binary_path: "build/mcpspy-linux-amd64"
    # Use --tui=false to disable TUI mode for tests (TUI is now the default)
    flags: ["--tui=false", "--log-level", "trace"]
    startup_wait_seconds: 2.0
    shutdown_timeout_seconds: 5.0

  validation:
    deepdiff:
      ignore_order: true
      exclude_regex_paths:
        # Exclude dynamic fields that change between runs
        - "root\\[\\d+\\]\\['timestamp'\\]"
        - "root\\[\\d+\\]\\['stdio_transport'\\]\\['from_pid'\\]"
        - "root\\[\\d+\\]\\['stdio_transport'\\]\\['to_pid'\\]"
        - "root\\[\\d+\\]\\['http_transport'\\]\\['pid'\\]"
        # Exclude version field (temporary until MCP server provides consistent versioning)
        - "root\\[\\d+\\]\\['result'\\]\\['serverInfo'\\]\\['version'\\]"
        # Exclude raw JSON field
        - "root\\[\\d+\\]\\['raw'\\]"

# Test scenarios
scenarios:
  # Stdio transport scenario
  - name: "stdio-fastmcp"
    description: "Test stdio transport with FastMCP Python server"

    # No pre_commands needed - client spawns server automatically

    traffic:
      command:
        [
          "bash",
          "-c",
          "tests/venv/bin/python tests/mcp_client.py --server 'tests/venv/bin/python tests/mcp_server.py'",
        ]
      working_directory: "."
      timeout_seconds: 30

    validation:
      expected_output_file: "expected_output_stdio.jsonl"
      message_count:
        min: 20
        max: 30

  # HTTP transport scenario
  - name: "http-fastmcp"
    description: "Test HTTP transport with FastMCP Python server (HTTPS with self-signed certs)"

    # Start HTTPS server before MCPSpy
    pre_commands:
      - command:
          [
            "tests/venv/bin/python",
            "-m",
            "uvicorn",
            "tests.mcp_server:app",
            "--host",
            "0.0.0.0",
            "--port",
            "12345",
            "--ssl-keyfile=tests/server.key",
            "--ssl-certfile=tests/server.crt",
            "--log-level",
            "error",
          ]
        background: true
        wait_seconds: 3.0

    traffic:
      command:
        [
          "tests/venv/bin/python",
          "tests/mcp_client.py",
          "--transport",
          "http",
          "--url",
          "https://127.0.0.1:12345/mcp",
        ]
      timeout_seconds: 30

    # Stop HTTP server after test completes
    post_commands:
      - command: ["pkill", "-f", "mcp_server.py"]

    validation:
      expected_output_file: "expected_output_http.jsonl"
      message_count:
        min: 20
        max: 30

  # Claude Code CLI scenario - comprehensive test for MCP, tools, and LLM
  - name: "claude-code"
    description: "Test Claude Code CLI with MCP servers, tool usage (Read, Bash), and LLM API calls"

    mcpspy:
      # Enable LLM monitoring to capture Anthropic API calls from Claude Code
      flags: ["--tui=false", "--log-level", "trace", "--llm"]

    traffic:
      # Run Claude Code with explicit tool usage instructions
      # This triggers:
      # 1. MCP server initialization (filesystem and deepwiki servers)
      # 2. Tool usage (Read to read test file, Bash to run echo)
      # 3. LLM API calls (Claude processing the prompt and generating response)
      # Using --print flag for non-interactive output
      command:
        [
          "bash",
          "-c",
          "npx -y @anthropic-ai/claude-code --print -p 'Execute these exact steps in order: 1) Use the Read tool to read tests/test_tool_data.txt and report its content. 2) Use Bash to run: echo MCPSPY-TEST-COMPLETE. Report both results concisely.' --strict-mcp-config --mcp-config tests/claude_config.json 2>&1",
        ]
      timeout_seconds: 30
      # Wait for tool execution and LLM response to complete
      post_traffic_wait_seconds: 5

    validation:
      message_count:
        min: 10

  # Gemini CLI scenario - comprehensive test for MCP, tools, and LLM
  # This test requires GEMINI_API_KEY environment variable to be set
  - name: "gemini-cli"
    description: "Test Gemini CLI with MCP servers, tool usage (Read, Bash), and LLM API calls"
    required_env_vars: ["GEMINI_API_KEY"]

    mcpspy:
      # Enable LLM monitoring to capture Gemini API calls
      flags: ["--tui=false", "--log-level", "trace", "--llm"]

    traffic:
      # Run Gemini CLI with explicit tool usage instructions
      # This triggers:
      # 1. MCP server initialization (filesystem and deepwiki servers)
      # 2. Tool usage (Read to read test file, Bash to run echo)
      # 3. LLM API calls (Gemini processing the prompt and generating response)
      # Using --yolo for auto-approval (no --sandbox to avoid namespace isolation issues with eBPF)
      # The tests/.gemini/settings.json contains MCP server configuration
      command:
        [
          "bash",
          "-c",
          "cd tests && npx -y @google/gemini-cli --yolo -o text 'Execute these exact steps in order: 1) Use the Read tool to read test_tool_data.txt and report its content. 2) Use Bash to run: echo MCPSPY-TEST-COMPLETE. Report both results concisely.' 2>&1",
        ]
      timeout_seconds: 120
      # Wait for tool execution and LLM response to complete
      post_traffic_wait_seconds: 5

    validation:
      message_count:
        min: 5

  # LLM API monitoring scenario (Anthropic)
  # This test requires CLAUDE_CODE_OAUTH_TOKEN environment variable to be set
  - name: "llm-anthropic"
    description: "Test LLM API monitoring with Anthropic (streaming and non-streaming)"
    required_env_vars: ["CLAUDE_CODE_OAUTH_TOKEN"]

    mcpspy:
      # Enable LLM monitoring
      flags: ["--tui=false", "--log-level", "trace", "--llm"]

    traffic:
      command:
        ["tests/venv/bin/python", "tests/llm_client.py", "--mode", "both"]
      working_directory: "."
      timeout_seconds: 120
      # Wait for API responses to complete
      post_traffic_wait_seconds: 5

    validation:
      expected_output_file: "expected_output_llm_anthropic.jsonl"
      message_count:
        min: 3
        max: 50
      deepdiff:
        ignore_order: true
        exclude_regex_paths:
          # Exclude dynamic fields
          - "root\\[\\d+\\]\\['timestamp'\\]"
          - "root\\[\\d+\\]\\['session_id'\\]"
          - "root\\[\\d+\\]\\['pid'\\]"
          # Exclude raw JSON field (contains full API payload)
          - "root\\[\\d+\\]\\['raw_json'\\]"

  # LLM API monitoring scenario (Gemini)
  # This test requires GEMINI_API_KEY environment variable to be set
  - name: "llm-gemini"
    description: "Test LLM API monitoring with Google Gemini (streaming and non-streaming)"
    required_env_vars: ["GEMINI_API_KEY"]

    mcpspy:
      # Enable LLM monitoring
      flags: ["--tui=false", "--log-level", "trace", "--llm"]

    traffic:
      command:
        [
          "tests/venv/bin/python",
          "tests/llm_gemini_client.py",
          "--mode",
          "both",
        ]
      working_directory: "."
      timeout_seconds: 120
      # Wait for API responses to complete
      post_traffic_wait_seconds: 5

    validation:
      expected_output_file: "expected_output_llm_gemini.jsonl"
      message_count:
        min: 3
        max: 50
      deepdiff:
        ignore_order: true
        exclude_regex_paths:
          # Exclude dynamic fields
          - "root\\[\\d+\\]\\['timestamp'\\]"
          - "root\\[\\d+\\]\\['session_id'\\]"
          - "root\\[\\d+\\]\\['pid'\\]"
          # Exclude raw JSON field (contains full API payload)
          - "root\\[\\d+\\]\\['raw_json'\\]"

  # Tool usage monitoring scenario (Claude Code)
  # Tests that tool invocations and results are captured when using --tools flag
  - name: "tools-claude-code"
    description: "Test tool usage monitoring with Claude Code (tool invocations and results)"

    mcpspy:
      # Enable tool monitoring to capture tool usage events from Claude Code
      flags: ["--tui=false", "--log-level", "trace", "--tools"]

    traffic:
      # Run Claude Code with explicit tool usage instructions
      # This triggers tool invocations (Read, Bash) and their results
      command:
        [
          "bash",
          "-c",
          "npx -y @anthropic-ai/claude-code --print -p 'Execute these exact steps in order: 1) Use the Read tool to read tests/test_tool_data.txt and report its content. 2) Use Bash to run: echo MCPSPY-TEST-COMPLETE. Report both results concisely.' --strict-mcp-config --mcp-config tests/claude_config.json 2>&1",
        ]
      timeout_seconds: 60
      # Wait for tool execution and results to complete
      post_traffic_wait_seconds: 5

    validation:
      # Validate message count only - the test captures MCP events from servers
      # plus tool usage events (invocation/result) from the LLM API.
      # Minimum 4 tool usage events expected: 2 invocations (Read, Bash) + 2 results
      message_count:
        min: 4

  # Tool usage monitoring scenario (Gemini CLI)
  # Tests that tool invocations and results are captured when using --tools flag
  # This test requires GEMINI_API_KEY environment variable to be set
  - name: "tools-gemini-cli"
    description: "Test tool usage monitoring with Gemini CLI (tool invocations and results)"

    pre_commands:
      - command:
          [
            "bash",
            "-c",
            'if [ -z "$GEMINI_API_KEY" ]; then echo ''ERROR: GEMINI_API_KEY environment variable is required''; exit 1; fi',
          ]
        timeout_seconds: 5

    mcpspy:
      # Enable tool monitoring to capture tool usage events from Gemini CLI
      flags: ["--tui=false", "--log-level", "trace", "--tools"]

    traffic:
      # Run Gemini CLI with explicit tool usage instructions
      # This triggers tool invocations (Read, Bash) and their results
      command:
        [
          "bash",
          "-c",
          "cd tests && npx -y @google/gemini-cli --yolo -o text 'Execute these exact steps in order: 1) Use the Read tool to read test_tool_data.txt and report its content. 2) Use Bash to run: echo MCPSPY-TEST-COMPLETE. Report both results concisely.' 2>&1",
        ]
      timeout_seconds: 120
      # Wait for tool execution and results to complete
      post_traffic_wait_seconds: 5

    validation:
      # Validate message count only - the test captures MCP events from servers
      # plus tool usage events (invocation/result) from the LLM API.
      # Minimum 4 tool usage events expected: 2 invocations (Read, Bash) + 2 results
      message_count:
        min: 4

  # Security/Prompt Injection detection scenario
  # This test requires HF_TOKEN environment variable to be set
  - name: "security-injection"
    description: "Test prompt injection detection with security monitoring enabled"
    required_env_vars: ["HF_TOKEN"]

    mcpspy:
      # Additional flags for security features - token comes from wrapper script
      flags:
        [
          "--tui=false",
          "--log-level",
          "trace",
          "--security",
          "--hf-token",
          "${HF_TOKEN}",
          "--security-threshold",
          "0.5",
        ]

    traffic:
      command:
        [
          "bash",
          "-c",
          "tests/venv/bin/python tests/mcp_client.py --server 'tests/venv/bin/python tests/mcp_server.py' --security-test",
        ]
      working_directory: "."
      timeout_seconds: 60
      # Wait for async HuggingFace API calls to complete.
      # Security analysis runs asynchronously by default. The HF API typically
      # takes 3-5s per request (cold start can be longer if model needs loading).
      # 15s allows for 2-3 analysis calls with margin for API latency variance.
      post_traffic_wait_seconds: 15

    validation:
      message_count:
        min: 19
        max: 22
      deepdiff:
        ignore_order: true
        exclude_regex_paths:
          # Exclude security alert dynamic fields (model scores vary slightly)
          - "root\\[\\d+\\]\\['risk_score'\\]"
          - "root\\[\\d+\\]\\['mcp_event'\\]\\['timestamp'\\]"
          - "root\\[\\d+\\]\\['mcp_event'\\]\\['stdio_transport'\\]"
          - "root\\[\\d+\\]\\['mcp_event'\\]\\['raw'\\]"
