# MCPSpy E2E Test Configuration
# ================================
# YAML-driven test configuration for MCPSpy end-to-end testing.
# This file defines test scenarios, their execution, and validation rules.

version: "1.0"

# Default settings applied to all scenarios
defaults:
  mcpspy:
    # Binary path relative to project root (where make is run)
    # Update this path if your platform is different (e.g., build/mcpspy-linux-arm64)
    binary_path: "build/mcpspy-linux-amd64"
    # Use --tui=false to disable TUI mode for tests (TUI is now the default)
    flags: ["--tui=false", "--log-level", "trace"]
    startup_wait_seconds: 2.0
    shutdown_timeout_seconds: 5.0

  validation:
    deepdiff:
      ignore_order: true
      exclude_regex_paths:
        # Exclude dynamic fields that change between runs
        - "root\\[\\d+\\]\\['timestamp'\\]"
        - "root\\[\\d+\\]\\['stdio_transport'\\]\\['from_pid'\\]"
        - "root\\[\\d+\\]\\['stdio_transport'\\]\\['to_pid'\\]"
        - "root\\[\\d+\\]\\['http_transport'\\]\\['pid'\\]"
        # Exclude version field (temporary until MCP server provides consistent versioning)
        - "root\\[\\d+\\]\\['result'\\]\\['serverInfo'\\]\\['version'\\]"
        # Exclude raw JSON field
        - "root\\[\\d+\\]\\['raw'\\]"

# Test scenarios
scenarios:
  # Stdio transport scenario
  - name: "stdio-fastmcp"
    description: "Test stdio transport with FastMCP Python server"

    # No pre_commands needed - client spawns server automatically

    traffic:
      command:
        [
          "bash",
          "-c",
          "tests/venv/bin/python tests/mcp_client.py --server 'tests/venv/bin/python tests/mcp_server.py'",
        ]
      working_directory: "."
      timeout_seconds: 30

    validation:
      expected_output_file: "expected_output_stdio.jsonl"
      message_count:
        min: 20
        max: 30

  # HTTP transport scenario
  - name: "http-fastmcp"
    description: "Test HTTP transport with FastMCP Python server (HTTPS with self-signed certs)"

    # Start HTTPS server before MCPSpy
    pre_commands:
      - command:
          [
            "tests/venv/bin/python",
            "-m",
            "uvicorn",
            "tests.mcp_server:app",
            "--host",
            "0.0.0.0",
            "--port",
            "12345",
            "--ssl-keyfile=tests/server.key",
            "--ssl-certfile=tests/server.crt",
            "--log-level",
            "error",
          ]
        background: true
        wait_seconds: 3.0

    traffic:
      command:
        [
          "tests/venv/bin/python",
          "tests/mcp_client.py",
          "--transport",
          "http",
          "--url",
          "https://127.0.0.1:12345/mcp",
        ]
      timeout_seconds: 30

    # Stop HTTP server after test completes
    post_commands:
      - command: ["pkill", "-f", "mcp_server.py"]

    validation:
      expected_output_file: "expected_output_http.jsonl"
      message_count:
        min: 20
        max: 30

  # Claude Code CLI scenario
  - name: "claude-code-init"
    description: "Test Claude Code CLI initialization with MCP servers"

    traffic:
      # Run Claude Code with the test config - it will initialize and connect to MCP servers
      # Provide a simple prompt and exit immediately to trigger MCP initialization
      command:
        [
          "bash",
          "-c",
          "echo 'exit' | npx -y @anthropic-ai/claude-code --strict-mcp-config --mcp-config tests/claude_config.json 2>&1",
        ]
      timeout_seconds: 30

    validation:
      message_count:
        min: 10

  # LLM API monitoring scenario (Anthropic)
  # This test requires CLAUDE_CODE_OAUTH_TOKEN environment variable to be set
  - name: "llm-anthropic"
    description: "Test LLM API monitoring with Anthropic (streaming and non-streaming)"

    mcpspy:
      # Enable LLM monitoring
      flags: ["--tui=false", "--log-level", "trace", "--llm"]

    traffic:
      command:
        ["tests/venv/bin/python", "tests/llm_client.py", "--mode", "both"]
      working_directory: "."
      timeout_seconds: 120
      # Wait for API responses to complete
      post_traffic_wait_seconds: 5

    validation:
      expected_output_file: "expected_output_llm_anthropic.jsonl"
      message_count:
        min: 3
        max: 50
      deepdiff:
        ignore_order: true
        exclude_regex_paths:
          # Exclude dynamic fields
          - "root\\[\\d+\\]\\['timestamp'\\]"
          - "root\\[\\d+\\]\\['session_id'\\]"
          - "root\\[\\d+\\]\\['pid'\\]"
          # Exclude raw JSON field (contains full API payload)
          - "root\\[\\d+\\]\\['raw_json'\\]"

  # LLM API monitoring scenario (Gemini)
  # This test requires GEMINI_API_KEY environment variable to be set
  - name: "llm-gemini"
    description: "Test LLM API monitoring with Google Gemini (streaming and non-streaming)"

    mcpspy:
      # Enable LLM monitoring
      flags: ["--tui=false", "--log-level", "trace", "--llm"]

    traffic:
      command:
        ["tests/venv/bin/python", "tests/llm_gemini_client.py", "--mode", "both"]
      working_directory: "."
      timeout_seconds: 120
      # Wait for API responses to complete
      post_traffic_wait_seconds: 5

    validation:
      expected_output_file: "expected_output_llm_gemini.jsonl"
      message_count:
        min: 3
        max: 50
      deepdiff:
        ignore_order: true
        exclude_regex_paths:
          # Exclude dynamic fields
          - "root\\[\\d+\\]\\['timestamp'\\]"
          - "root\\[\\d+\\]\\['session_id'\\]"
          - "root\\[\\d+\\]\\['pid'\\]"
          # Exclude raw JSON field (contains full API payload)
          - "root\\[\\d+\\]\\['raw_json'\\]"

  # Security/Prompt Injection detection scenario
  # This test requires HF_TOKEN environment variable to be set
  - name: "security-injection"
    description: "Test prompt injection detection with security monitoring enabled"

    pre_commands:
      - command:
          [
            "bash",
            "-c",
            'if [ -z "$HF_TOKEN" ]; then echo ''ERROR: HF_TOKEN environment variable is required''; exit 1; fi',
          ]
        timeout_seconds: 5

    mcpspy:
      # Additional flags for security features - token comes from wrapper script
      flags:
        [
          "--tui=false",
          "--log-level",
          "trace",
          "--security",
          "--hf-token",
          "${HF_TOKEN}",
          "--security-threshold",
          "0.5",
        ]

    traffic:
      command:
        [
          "bash",
          "-c",
          "tests/venv/bin/python tests/mcp_client.py --server 'tests/venv/bin/python tests/mcp_server.py' --security-test",
        ]
      working_directory: "."
      timeout_seconds: 60
      # Wait for async HuggingFace API calls to complete.
      # Security analysis runs asynchronously by default. The HF API typically
      # takes 3-5s per request (cold start can be longer if model needs loading).
      # 15s allows for 2-3 analysis calls with margin for API latency variance.
      post_traffic_wait_seconds: 15

    validation:
      message_count:
        min: 19
        max: 22
      deepdiff:
        ignore_order: true
        exclude_regex_paths:
          # Exclude security alert dynamic fields (model scores vary slightly)
          - "root\\[\\d+\\]\\['risk_score'\\]"
          - "root\\[\\d+\\]\\['mcp_event'\\]\\['timestamp'\\]"
          - "root\\[\\d+\\]\\['mcp_event'\\]\\['stdio_transport'\\]"
          - "root\\[\\d+\\]\\['mcp_event'\\]\\['raw'\\]"
